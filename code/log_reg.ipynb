{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphrase Detection on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kamal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "#nalla\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "# from pyemd import emd\n",
    "from gensim import corpora, models, similarities\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pulp\n",
    "\n",
    "#sowrya\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from six import iteritems\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "* each tweet is considered as a document\n",
    "* making a list of all the tweets and finding the idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_processing():\n",
    "    f = open('./glove25.txt','r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        word = line[0]\n",
    "        embedding = np.array([float(val) for val in line[1:]])\n",
    "        model[word] =  embedding\n",
    "    print(len(model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193514\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.data', sep='\\t', lineterminator='\\n', names=['Topic_Id', 'Topic_Name',  'Sent_1', 'Sent_2', 'Label', 'Sent_1_tag','Sent_2_tag'])\n",
    "df2 = df[['Sent_1', 'Sent_2', 'Label']]\n",
    "model = glove_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Tweets\n",
    "\n",
    "* Preprocess the tweets with respect to .... to get a 4D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(labels):\n",
    "    '''returns binary labels 0 or 1'''\n",
    "    new_labels = np.array([])\n",
    "    for i in labels:\n",
    "        if type(i) == str and len(i) > 1:\n",
    "            i = i[1]\n",
    "        if int(i) >= 3:\n",
    "            new_labels = np.append(new_labels, int(1))\n",
    "        else:\n",
    "            new_labels = np.append(new_labels, int(0))\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13063,)\n"
     ]
    }
   ],
   "source": [
    "train_labels = process_labels(df2.Label)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Distance for average of sentence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec(sent, model):\n",
    "    ans = np.zeros(25)\n",
    "    count = 0\n",
    "    if len(sent) == 0:\n",
    "        return ans\n",
    "    for i, word in enumerate(sent.split()):\n",
    "        if word not in model:\n",
    "            continue\n",
    "        else:\n",
    "            ans += np.array(model[word])\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        ans = ans / count\n",
    "    return ans, count\n",
    "\n",
    "\n",
    "def cosine_dist(vec1, vec2):\n",
    "    ans = 0\n",
    "    mod1 = 0\n",
    "    mod2 = 0\n",
    "    for i in range(vec1.size):\n",
    "        ans += vec1[i] * vec2[i]\n",
    "        mod1 += vec1[i] * vec1[i]\n",
    "        mod2 += vec2[i] * vec2[i]\n",
    "    if ans == 0:\n",
    "        return 0\n",
    "    return ans / (math.sqrt(mod1) * math.sqrt(mod2))\n",
    "\n",
    "\n",
    "def cosine_data(df, model):\n",
    "    arr = np.array([]) #has the cosine distance values for all the tweet pairs\n",
    "    for i in range(df.Sent_1.size):\n",
    "        vec1, count1 = sent_vec(df.Sent_1[i], model)\n",
    "        vec2, count2 = sent_vec(df.Sent_2[i], model)\n",
    "        ans = cosine_dist(vec1, vec2)\n",
    "        arr = np.append(arr, ans)\n",
    "#         if i == 7:\n",
    "#             print(i, df.Sent_1[i], \"sdfsdf\", df.Sent_2[i], vec1, vec2, count1, count2, ans)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word movers distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleindexing = lambda m, i, j: m*i+j\n",
    "unpackindexing = lambda m, k: (k/m, k % m)\n",
    "\n",
    "def tokens_to_fracdict(tokens):\n",
    "    cntdict = defaultdict(lambda : 0)\n",
    "    for token in tokens:\n",
    "        cntdict[token] += 1\n",
    "    totalcnt = sum(cntdict.values())\n",
    "    return {token: float(cnt)/totalcnt for token, cnt in cntdict.items()}\n",
    "\n",
    "# use PuLP\n",
    "def word_mover_distance_probspec(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=None):\n",
    "    all_tokens = list(set(first_sent_tokens+second_sent_tokens))\n",
    "    wordvecs = {}\n",
    "    for token in all_tokens:\n",
    "        try:\n",
    "            wordvecs[token] = wvmodel[token]\n",
    "        except KeyError:\n",
    "            wordvecs[token] = 0\n",
    "\n",
    "    first_sent_buckets = tokens_to_fracdict(first_sent_tokens)\n",
    "    second_sent_buckets = tokens_to_fracdict(second_sent_tokens)\n",
    "\n",
    "    T= pulp.LpVariable.dicts('T_matrix', list(product(all_tokens, all_tokens)), lowBound=0)\n",
    "\n",
    "    prob = pulp.LpProblem('WMD', sense=pulp.LpMinimize)\n",
    "    try:\n",
    "        prob += pulp.lpSum([T[token1, token2]*euclidean(wordvecs[token1], wordvecs[token2])\n",
    "                        for token1, token2 in product(all_tokens, all_tokens)])\n",
    "    except KeyError:\n",
    "        prob+=0\n",
    "    for token2 in second_sent_buckets:\n",
    "        prob += pulp.lpSum([T[token1, token2] for token1 in first_sent_buckets])==second_sent_buckets[token2]\n",
    "    for token1 in first_sent_buckets:\n",
    "        prob += pulp.lpSum([T[token1, token2] for token2 in second_sent_buckets])==first_sent_buckets[token1]\n",
    "\n",
    "    if lpFile!=None:\n",
    "        prob.writeLP(lpFile)\n",
    "    prob.solve()\n",
    "    if(prob == None):\n",
    "        print(\"yes\")\n",
    "    return prob\n",
    "\n",
    "def word_mover_distance(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=None):\n",
    "    prob = word_mover_distance_probspec(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=lpFile)\n",
    "    return pulp.value(prob.objective)\n",
    "\n",
    "def arr2_creator(df, model):\n",
    "    arr2 = np.array([])\n",
    "    stop_words = stopwords.words('english')\n",
    "    dist=0\n",
    "    l = open('./data/train.data','r')\n",
    "    j = 0\n",
    "    total = 0\n",
    "    for i in range(df.Sent_1.size):\n",
    "        sent1 = df.Sent_1[i].split()\n",
    "        sent2 = df.Sent_2[i].split()\n",
    "        sent1 = [w for w in sent1 if w not in stop_words]\n",
    "        sent2 = [w for w in sent2 if w not in stop_words]\n",
    "        temp = word_mover_distance(sent1, sent2, model)\n",
    "        if temp == None:\n",
    "            temp = total / j\n",
    "        else:\n",
    "            total += temp\n",
    "            j += 1\n",
    "        arr2 = np.append(arr2, temp)\n",
    "    return arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet based noun similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "    # if tag.startswith('V'):\n",
    "    #     return 'v'\n",
    "    # if tag.startswith('J'):\n",
    "    #     return 'a'\n",
    "    # if tag.startswith('R'):\n",
    "    #     return 'r'\n",
    "    return None\n",
    "\n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "#         print('here')\n",
    "        return None\n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "        print('here')\n",
    "    except:\n",
    "#         print(wn.synsets(word, wn_tag))\n",
    "#         print('here_1')\n",
    "        return None\n",
    "\n",
    "def shortest_hypernym_paths(synset):\n",
    "    # hyp = synset.hypernyms()\n",
    "    # hyp_1 = synset.instance_hypernyms()\n",
    "    if synset._name == '*ROOT*':\n",
    "        return {synset: 0}\n",
    "    queue = deque([(synset,0)])\n",
    "    path = {}\n",
    "    while queue:\n",
    "        s, depth = queue.popleft()\n",
    "        if s in path:\n",
    "            continue\n",
    "        path[s] = depth\n",
    "        depth += 1\n",
    "        queue.extend((hyp, depth) for hyp in s.hypernyms())\n",
    "        queue.extend((hyp, depth) for hyp in s.instance_hypernyms())\n",
    "    # simulate_root = True\n",
    "    # # if simulate_root:\n",
    "    # #     fake_synset = wn.synset(None)\n",
    "    # #     fake_synset._name = '*ROOT*'\n",
    "    # #     path[fake_synset] = max(path.values()) + 1\n",
    "    return path\n",
    "\n",
    "def shortest_path_distance(synset_1,synset_2):\n",
    "    if synset_1 == synset_2:\n",
    "        return 0\n",
    "    dist_dict1 = shortest_hypernym_paths(synset_1)\n",
    "    dist_dict2 = shortest_hypernym_paths(synset_2)\n",
    "    inf = float('inf')\n",
    "    path_distance = inf\n",
    "    for synset, d1 in iteritems(dist_dict1):\n",
    "        d2 = dist_dict2.get(synset, inf)\n",
    "        path_distance = min(path_distance, d1 + d2)\n",
    "    return None if math.isinf(path_distance) else path_distance\n",
    "\n",
    "def path_similarity(synset_1,synset_2):\n",
    "    distance = shortest_path_distance(synset_1,synset_2)\n",
    "    if distance is None or distance < 0:\n",
    "        return None\n",
    "    return 1.0/(distance + 1)\n",
    "\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    sentence1, sentence2 = pos_tag(word_tokenize(sentence1)), pos_tag(word_tokenize(sentence2))\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    score, count = 0.0, 0\n",
    "    for syn1 in synsets1:\n",
    "        arr_simi_score = []\n",
    "        for syn2 in synsets2:\n",
    "            simi_score = path_similarity(syn1,syn2)\n",
    "            if simi_score is not None:\n",
    "                arr_simi_score.append(simi_score)\n",
    "        if(len(arr_simi_score) > 0):\n",
    "            best = max(arr_simi_score)\n",
    "            score += best\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        score /= count\n",
    "    return score\n",
    "\n",
    "def arr3_creator(df):\n",
    "    arr3 = np.array([])\n",
    "    s_1 = \"EJ Manuel the 1st QB to go in this draft\"\n",
    "    s_2 = \"if EJ is the 1st QB off the board\"\n",
    "    for i in range(df.Sent_1.size):\n",
    "#     val = (sentence_similarity(s_2, s_1) + sentence_similarity(s_1, s_2))/2\n",
    "        val = (sentence_similarity(df.Sent_1[i], df.Sent_2[i]) + sentence_similarity(df.Sent_2[i], df.Sent_1[i]))/2\n",
    "#         print(df.Sent_1[i], df.Sent_2[i], val)\n",
    "        arr3 = np.append(arr3, val)\n",
    "    return arr3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vectors\n",
    "* Appending all values for each tweet pair to create a 4D vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13063,)\n"
     ]
    }
   ],
   "source": [
    "arr1 = cosine_data(df2, model)\n",
    "print(arr1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13063,)\n"
     ]
    }
   ],
   "source": [
    "arr2 = arr2_creator(df2, model)\n",
    "print(arr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13063,)\n"
     ]
    }
   ],
   "source": [
    "arr3 = arr3_creator(df2)\n",
    "print(arr3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(arr1, arr2, arr3):\n",
    "    new_arr = np.vstack((arr1, arr2, arr3))\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 13063)\n"
     ]
    }
   ],
   "source": [
    "train_data = create_vectors(arr1, arr2, arr3) #(3,N) dimensions\n",
    "print(train_data.shape)\n",
    "#each column is a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = create_vectors(np.zeros(arr1.shape), arr2, arr3) #(3,N) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = create_vectors(arr1, np.zeros(arr2.shape), arr3) #(3,N) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3 = create_vectors(arr1, arr2, np.zeros(arr3.shape)) #(3,N) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data4 = create_vectors(arr1, np.zeros(arr2.shape), np.zeros(arr3.shape)) #(3,N) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data5 = create_vectors(np.zeros(arr1.shape), arr2, np.zeros(arr3.shape)) #(3,N) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data6 = create_vectors(np.zeros(arr1.shape), np.zeros(arr2.shape), arr3) #(3,N) dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, train_data, train_labels):\n",
    "    ans = 0\n",
    "    for i in range(train_labels.size):\n",
    "#         print(np.dot(model, train_data[:, i]))\n",
    "        val = sigmoid(np.dot(model, train_data[:, i]))\n",
    "        ans += (train_labels[i] * np.log(val)) + ((1-train_labels[i]) * np.log(1-val))\n",
    "    return abs(ans)\n",
    "\n",
    "def classify(val):\n",
    "    if val >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sigmoid(val):\n",
    "    ans = 1 / (1 + np.exp(-val))\n",
    "    return ans\n",
    "\n",
    "def loss_gradient(model, train_data, train_labels):\n",
    "    loss = np.zeros(model.size)\n",
    "    for j in range(train_labels.size):\n",
    "#         print(j, train_data[:, j])\n",
    "        loss = loss + train_data[:, j] * (sigmoid(np.dot(model, train_data[:, j])) - train_labels[j])\n",
    "#         if loss[1] == None:\n",
    "#             print (j, train_data[:,j])\n",
    "    return loss\n",
    "\n",
    "def log_reg(train_data, train_labels):\n",
    "    '''returns a trained model'''\n",
    "    eta = 0.00005\n",
    "    model = np.random.rand(3)\n",
    "    curr_loss = loss(model, train_data, train_labels)\n",
    "    prev_loss = curr_loss - 100\n",
    "    while abs(curr_loss - prev_loss) > 1:\n",
    "        print(abs(curr_loss - prev_loss))\n",
    "#     while loss(model, train_data, train_labels) > 0.1:\n",
    "        val = loss_gradient(model, train_data, train_labels)\n",
    "        model -= eta * val\n",
    "        prev_loss = curr_loss\n",
    "        curr_loss = loss(model, train_data, train_labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "19302.17987802352\n",
      "1535.636791038457\n",
      "5.654509099948882\n",
      "2.547519463608296\n",
      "2.4022999703756795\n",
      "2.3372411729033047\n",
      "2.2760281244181897\n",
      "2.2168219311670327\n",
      "2.159501190712035\n",
      "2.1039879786476376\n",
      "2.0502092278675264\n",
      "1.998095538504458\n",
      "1.9475809354489684\n",
      "1.8986026760376262\n",
      "1.8511010679058018\n",
      "1.8050193014742035\n",
      "1.7603032897359299\n",
      "1.7169015192803272\n",
      "1.6747649090602863\n",
      "1.6338466778533984\n",
      "1.5941022193128447\n",
      "1.5554889845734579\n",
      "1.5179663713734044\n",
      "1.481495620196256\n",
      "1.446039715578081\n",
      "1.4115632938655835\n",
      "1.3780325562956932\n",
      "1.3454151863361403\n",
      "1.3136802728413386\n",
      "1.2827982366452488\n",
      "1.2527407623128965\n",
      "1.2234807324475696\n",
      "1.1949921673876815\n",
      "1.1672501669672783\n",
      "1.1402308563028782\n",
      "1.1139113343879217\n",
      "1.0882696252519963\n",
      "1.0632846329945096\n",
      "1.0389360974659212\n",
      "1.0152045545592046\n"
     ]
    }
   ],
   "source": [
    "lr_model = log_reg(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "8685.361839845002\n",
      "87.62052378273347\n",
      "7.621568359057164\n",
      "5.515122088274438\n",
      "5.22653848520622\n",
      "5.0239685023198035\n",
      "4.832782901848077\n",
      "4.649196070119615\n",
      "4.4727534271778495\n",
      "4.303167401743849\n",
      "4.140167813028711\n",
      "3.983495032094652\n",
      "3.8328994783050803\n",
      "3.688141295921014\n",
      "3.548990015387062\n",
      "3.415224217512332\n",
      "3.286631202206081\n",
      "3.1630066669658845\n",
      "3.0441543946799356\n",
      "2.9298859488308153\n",
      "2.8200203795713605\n",
      "2.714383937472121\n",
      "2.6128097977880316\n",
      "2.515137792052883\n",
      "2.421214149860134\n",
      "2.330891248999251\n",
      "2.244027373935751\n",
      "2.1604864829778307\n",
      "2.080137984038629\n",
      "2.0028565181037266\n",
      "1.928521750445725\n",
      "1.857018170117044\n",
      "1.788234896736867\n",
      "1.7220654941183966\n",
      "1.6584077915440503\n",
      "1.5971637123757318\n",
      "1.5382391071607344\n",
      "1.48154359621185\n",
      "1.4269904161692466\n",
      "1.3744962732826025\n",
      "1.3239812028214146\n",
      "1.2753684336075821\n",
      "1.2285842583069098\n",
      "1.1835579085473\n",
      "1.1402214358358833\n",
      "1.0985095959576938\n",
      "1.0583597398235725\n",
      "1.019711707112947\n"
     ]
    }
   ],
   "source": [
    "lr_model1 = log_reg(train_data1, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "450.3062813270135\n",
      "313.5602971813605\n",
      "218.33834572209526\n",
      "152.73701633410565\n",
      "107.66961565557722\n",
      "76.64972240124735\n",
      "55.20166981493094\n",
      "40.28456849455233\n",
      "29.842482837924763\n",
      "22.483978621691676\n",
      "17.263347152225833\n",
      "13.534061901124005\n",
      "10.85126323190434\n",
      "8.906848992548476\n",
      "7.486090884925034\n",
      "6.438459825601967\n",
      "5.657867268467271\n",
      "5.069184588596727\n",
      "4.618978738711121\n",
      "4.269101292936284\n",
      "3.992223390685467\n",
      "3.768707567185629\n",
      "3.584404481733145\n",
      "3.429093667162306\n",
      "3.295375366540611\n",
      "3.177880015462506\n",
      "3.07270246796179\n",
      "2.976995913782048\n",
      "2.888679689541277\n",
      "2.806228586729958\n",
      "2.7285206427977755\n",
      "2.6547270077453504\n",
      "2.5842321432628523\n",
      "2.5165759342289675\n",
      "2.4514116507361905\n",
      "2.3884753959209775\n",
      "2.327563882922732\n",
      "2.268518259643315\n",
      "2.2112123292126853\n",
      "2.155543964406206\n",
      "2.1014288496189693\n",
      "2.04879591284498\n",
      "1.997583993371336\n",
      "1.947739404402455\n",
      "1.8992141524731778\n",
      "1.8519646328613817\n",
      "1.805950672369363\n",
      "1.7611348268537768\n",
      "1.7174818622188468\n",
      "1.6749583717064525\n",
      "1.6335324901074273\n",
      "1.5931736813781754\n",
      "1.5538525778174517\n",
      "1.5155408572190936\n",
      "1.4782111491085743\n",
      "1.4418369608310968\n",
      "1.4063926186463505\n",
      "1.3718532204247822\n",
      "1.3381945957698917\n",
      "1.3053932732118483\n",
      "1.2734264509663262\n",
      "1.2422719712931212\n",
      "1.2119082982890177\n",
      "1.1823144964864696\n",
      "1.1534702116478002\n",
      "1.125355652898179\n",
      "1.097951575310617\n",
      "1.071239263887037\n",
      "1.0452005184870359\n",
      "1.0198176376597985\n"
     ]
    }
   ],
   "source": [
    "lr_model2 = log_reg(train_data2, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "3858.0261010559834\n",
      "4.987315346509604\n",
      "1.968169372436023\n",
      "1.764448102600909\n",
      "1.685395327887818\n",
      "1.6139709338049215\n",
      "1.5455631362774511\n",
      "1.4798996683603036\n",
      "1.4168748961001256\n",
      "1.3563925168355127\n",
      "1.2983593723720332\n",
      "1.2426851178252036\n",
      "1.1892821565052145\n",
      "1.1380655932052832\n",
      "1.0889531880320646\n",
      "1.0418653076385453\n"
     ]
    }
   ],
   "source": [
    "lr_model3 = log_reg(train_data3, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "719.0709431657269\n",
      "556.3384653130361\n",
      "426.2493302237526\n",
      "324.74269378010104\n",
      "246.8029333425784\n",
      "187.53763173399784\n",
      "142.6980374864179\n",
      "108.83088942314316\n",
      "83.23820439996962\n",
      "63.86105054863765\n",
      "49.1490983235708\n",
      "37.942982880987984\n",
      "29.377983151567605\n",
      "22.809057027428025\n",
      "17.75412519823476\n",
      "13.851830499274001\n",
      "10.830332968817856\n",
      "8.484334745921842\n",
      "6.658169287722558\n",
      "5.233333239816602\n",
      "4.119266711061755\n",
      "3.2465101919133303\n",
      "2.56160425100461\n",
      "2.023271456760085\n",
      "1.5995454482945206\n",
      "1.2656027067023388\n",
      "1.0021180450512475\n"
     ]
    }
   ],
   "source": [
    "lr_model4 = log_reg(train_data4, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "4807.717838277778\n",
      "12.806094247069268\n"
     ]
    }
   ],
   "source": [
    "lr_model5 = log_reg(train_data5, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "130.6148563950137\n",
      "117.53264886976649\n",
      "105.59735972069939\n",
      "94.74912915325149\n",
      "84.92129408141773\n",
      "76.04328268296376\n",
      "68.04302272892346\n",
      "60.84886505012764\n",
      "54.39105451231808\n",
      "48.60279953567078\n",
      "43.420999934811334\n",
      "38.786694350188554\n",
      "34.64528525750211\n",
      "30.946593431590372\n",
      "27.6447863788635\n",
      "24.698217604864112\n",
      "22.069206360712997\n",
      "19.72378105914686\n",
      "17.631403996458175\n",
      "15.7646904397443\n",
      "14.099131418193792\n",
      "12.612826649105045\n",
      "11.286231758334907\n",
      "10.101922278554412\n",
      "9.044375637780831\n",
      "8.09977146046731\n",
      "7.255809873631733\n",
      "6.501547092804685\n",
      "5.827247298006114\n",
      "5.224249657307155\n",
      "4.684849303088413\n",
      "4.202191033307827\n",
      "3.7701745635367843\n",
      "3.3833701953626587\n",
      "3.036943846886061\n",
      "2.726590458822102\n",
      "2.448474890587022\n",
      "2.1991794776931783\n",
      "1.9756575202973181\n",
      "1.7751920396785863\n",
      "1.595359205010027\n",
      "1.4339959015123895\n",
      "1.289170969865154\n",
      "1.159159693725087\n",
      "1.0424211631852813\n"
     ]
    }
   ],
   "source": [
    "lr_model6 = log_reg(train_data6, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31640635 -0.44107213  0.8651805 ]\n"
     ]
    }
   ],
   "source": [
    "print(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test.data', sep='\\t', lineterminator='\\n', names=['Topic_Id', 'Topic_Name',  'Sent_1', 'Sent_2', 'Label', 'Sent_1_tag','Sent_2_tag'])\n",
    "test_pairs = df[['Sent_1', 'Sent_2']]\n",
    "test_labels = process_labels(df.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(972,)\n"
     ]
    }
   ],
   "source": [
    "test_arr1 = cosine_data(test_pairs, model)\n",
    "print(test_arr1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(972,)\n"
     ]
    }
   ],
   "source": [
    "test_arr2 = arr2_creator(test_pairs, model)\n",
    "print(test_arr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(972,)\n"
     ]
    }
   ],
   "source": [
    "test_arr3 = arr3_creator(test_pairs)\n",
    "print(test_arr3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_vectors(test_arr1, test_arr2, test_arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = create_vectors(np.zeros(test_arr1.shape), test_arr2, test_arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = create_vectors(test_arr1, np.zeros(test_arr2.shape), test_arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data3 = create_vectors(test_arr1, test_arr2, np.zeros(test_arr3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data4 = create_vectors(test_arr1, np.zeros(test_arr2.shape), np.zeros(test_arr3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data5 = create_vectors(np.zeros(test_arr1.shape), test_arr2, np.zeros(test_arr3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data6 = create_vectors(np.zeros(test_arr1.shape), np.zeros(test_arr2.shape), test_arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, test_data, test_labels):\n",
    "    predict = np.array([])\n",
    "    for i in range(test_labels.size):\n",
    "        val = classify(sigmoid(np.dot(model, test_data[:, i])))\n",
    "        predict = np.append(predict, val)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      1.00      0.82       663\n",
      "         1.0       0.88      0.05      0.09       309\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       972\n",
      "   macro avg       0.79      0.52      0.45       972\n",
      "weighted avg       0.75      0.70      0.59       972\n",
      "\n",
      "0.6954732510288066\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model, test_data, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.99      0.82       663\n",
      "         1.0       0.80      0.06      0.12       309\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       972\n",
      "   macro avg       0.75      0.53      0.47       972\n",
      "weighted avg       0.73      0.70      0.60       972\n",
      "\n",
      "0.6975308641975309\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model1, test_data1, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.94      0.79       663\n",
      "         1.0       0.37      0.08      0.13       309\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       972\n",
      "   macro avg       0.53      0.51      0.46       972\n",
      "weighted avg       0.59      0.66      0.58       972\n",
      "\n",
      "0.6646090534979424\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model2, test_data2, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      1.00      0.81       663\n",
      "         1.0       1.00      0.01      0.01       309\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       972\n",
      "   macro avg       0.84      0.50      0.41       972\n",
      "weighted avg       0.78      0.68      0.56       972\n",
      "\n",
      "0.684156378600823\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model3, test_data3, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.94      0.79       663\n",
      "         1.0       0.37      0.07      0.12       309\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       972\n",
      "   macro avg       0.53      0.51      0.46       972\n",
      "weighted avg       0.58      0.66      0.58       972\n",
      "\n",
      "0.6646090534979424\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model4, test_data4, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      1.00      0.81       663\n",
      "         1.0       1.00      0.00      0.01       309\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       972\n",
      "   macro avg       0.84      0.50      0.41       972\n",
      "weighted avg       0.78      0.68      0.56       972\n",
      "\n",
      "0.6831275720164609\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model5, test_data5, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.86      0.75       663\n",
      "         1.0       0.21      0.08      0.11       309\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       972\n",
      "   macro avg       0.44      0.47      0.43       972\n",
      "weighted avg       0.52      0.61      0.55       972\n",
      "\n",
      "0.6141975308641975\n"
     ]
    }
   ],
   "source": [
    "predicted_arr = testing(lr_model6, test_data6, test_labels)\n",
    "print(skm.classification_report(test_labels, predicted_arr))\n",
    "print(skm.accuracy_score(test_labels, predicted_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
